{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 50 are the primary variables including all of the dummy variables. The next 560 are interactions with the dummy variables. The final variables are the adjacency variables that aren't in the primary variable section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"aae98c45-df40-4ee2-87c1-489a939c0555\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      Bokeh.$(\"#aae98c45-df40-4ee2-87c1-489a939c0555\").text(\"BokehJS successfully loaded.\");\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"aae98c45-df40-4ee2-87c1-489a939c0555\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'aae98c45-df40-4ee2-87c1-489a939c0555' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.2.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#aae98c45-df40-4ee2-87c1-489a939c0555\").text(\"BokehJS is loading...\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === \"1\") {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (!force) {\n",
       "      var cell = $(\"#aae98c45-df40-4ee2-87c1-489a939c0555\").parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import bokeh\n",
    "\n",
    "from bokeh.io import show, output_notebook, output_file\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.charts import Bar\n",
    "from bokeh.charts.attributes import cat\n",
    "from bokeh.models import HoverTool\n",
    "output_notebook ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124011, 825)\n"
     ]
    }
   ],
   "source": [
    "combined = pd.read_csv(\"new data/Final_Project_Variables - combined.csv\")\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 825)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>interest_code</th>\n",
       "      <th>days_between_adj_5</th>\n",
       "      <th>log_price_adj_3</th>\n",
       "      <th>interest_adj_13</th>\n",
       "      <th>feature_count_adj_25</th>\n",
       "      <th>bathrooms_adj_4</th>\n",
       "      <th>descript_len_adj_11</th>\n",
       "      <th>bedrooms_adj_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bathrooms_adj_21</th>\n",
       "      <th>bathrooms_adj_22</th>\n",
       "      <th>bathrooms_adj_23</th>\n",
       "      <th>bathrooms_adj_24</th>\n",
       "      <th>bathrooms_adj_25</th>\n",
       "      <th>bathrooms_adj_26</th>\n",
       "      <th>bathrooms_adj_27</th>\n",
       "      <th>bathrooms_adj_28</th>\n",
       "      <th>bathrooms_adj_29</th>\n",
       "      <th>bathrooms_adj_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7170325</td>\n",
       "      <td>2</td>\n",
       "      <td>1318</td>\n",
       "      <td>23.485804</td>\n",
       "      <td>19</td>\n",
       "      <td>130</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5398</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7092344</td>\n",
       "      <td>1</td>\n",
       "      <td>1173</td>\n",
       "      <td>24.941265</td>\n",
       "      <td>18</td>\n",
       "      <td>168</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7174</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7158677</td>\n",
       "      <td>2</td>\n",
       "      <td>1170</td>\n",
       "      <td>24.302001</td>\n",
       "      <td>21</td>\n",
       "      <td>127</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6583</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>7211212</td>\n",
       "      <td>2</td>\n",
       "      <td>1189</td>\n",
       "      <td>23.654460</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5388</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>7225292</td>\n",
       "      <td>1</td>\n",
       "      <td>1207</td>\n",
       "      <td>25.326354</td>\n",
       "      <td>17</td>\n",
       "      <td>195</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6230</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 825 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   observation  listing_id  interest_code  days_between_adj_5  \\\n",
       "0            4     7170325              2                1318   \n",
       "1            6     7092344              1                1173   \n",
       "2            9     7158677              2                1170   \n",
       "3           10     7211212              2                1189   \n",
       "4           15     7225292              1                1207   \n",
       "\n",
       "   log_price_adj_3  interest_adj_13  feature_count_adj_25  bathrooms_adj_4  \\\n",
       "0        23.485804               19                   130              4.0   \n",
       "1        24.941265               18                   168              6.0   \n",
       "2        24.302001               21                   127              4.0   \n",
       "3        23.654460               15                    46              4.5   \n",
       "4        25.326354               17                   195              6.0   \n",
       "\n",
       "   descript_len_adj_11  bedrooms_adj_3        ...         bathrooms_adj_21  \\\n",
       "0                 5398               4        ...                     21.0   \n",
       "1                 7174               7        ...                     23.0   \n",
       "2                 6583               5        ...                     25.0   \n",
       "3                 5388               5        ...                     23.0   \n",
       "4                 6230               5        ...                     24.0   \n",
       "\n",
       "   bathrooms_adj_22  bathrooms_adj_23  bathrooms_adj_24  bathrooms_adj_25  \\\n",
       "0              22.0              23.0              24.0              25.0   \n",
       "1              24.0              26.0              27.0              28.0   \n",
       "2              26.0              27.0              28.0              31.0   \n",
       "3              24.0              25.0              26.0              27.0   \n",
       "4              25.0              26.0              27.0              28.0   \n",
       "\n",
       "   bathrooms_adj_26  bathrooms_adj_27  bathrooms_adj_28  bathrooms_adj_29  \\\n",
       "0              26.0              27.0              28.0              29.0   \n",
       "1              29.0              30.0              31.0              33.0   \n",
       "2              34.0              35.0              36.0              37.0   \n",
       "3              28.0              29.0              30.0              31.0   \n",
       "4              29.0              30.0              31.0              32.0   \n",
       "\n",
       "   bathrooms_adj_30  \n",
       "0              30.0  \n",
       "1              34.0  \n",
       "2              38.0  \n",
       "3              32.0  \n",
       "4              33.0  \n",
       "\n",
       "[5 rows x 825 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all = pd.read_csv(\"new data/Final_Project_Variables - train.csv\")\n",
    "print(train_all.shape)\n",
    "train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74659, 825)\n"
     ]
    }
   ],
   "source": [
    "holdout = pd.read_csv(\"new data/Final_Project_Variables - test.csv\")\n",
    "print(holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(train_all.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of Lows:  69.46830928837737\n",
      "percentage of Mediums:  22.752877289674178\n",
      "percentage of Highs:  7.778813421948453\n"
     ]
    }
   ],
   "source": [
    "interest = train_all[\"interest_code\"]\n",
    "print(\"percentage of Lows: \", len(interest[interest== 1])/len(interest) * 100)\n",
    "print(\"percentage of Mediums: \", len(interest[interest== 2])/len(interest) * 100)\n",
    "print(\"percentage of Highs: \", len(interest[interest== 3])/len(interest) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert from pandas to numpy arrays: \n",
    "\n",
    "mat_train = train_all.as_matrix()\n",
    "X_train_all = mat_train[:,3:]\n",
    "y_train_all = mat_train[:, 2]\n",
    "mat_holdout = holdout.as_matrix()\n",
    "X_holdout = mat_holdout[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Because MLP is sensitive to scaling, scale all the predictors in the train and test data:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train_all)  \n",
    "X_train_all_scale = scaler.transform(X_train_all)  \n",
    "X_holdout_scale = scaler.transform(X_holdout)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test/train split:   \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_all_scale, y_train_all)    # could also try stratified K_fold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37014, 822)\n",
      "(12338, 822)\n",
      "(49352, 825)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline (Random) Classifier Performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline log loss:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78391113651128785"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_y1 = len(y_train[y_train== 1])/len(y_train)\n",
    "per_y2 = len(y_train[y_train== 2])/len(y_train)\n",
    "per_y3 = len(y_train[y_train== 3])/len(y_train)\n",
    "\n",
    "y1 = len(y_train[y_train== 1])\n",
    "y2 = len(y_train[y_train== 2])\n",
    "y3 = len(y_train[y_train== 3])\n",
    "\n",
    "print(\"baseline log loss:\")\n",
    "- (1/X_train.shape[0])*(np.log(per_y1)*y1  + np.log(per_y2)*y2 + np.log(per_y3)*y3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Neural Net:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The advantages of Multi-layer Perceptron are:\n",
    "- Capability to learn non-linear models.\n",
    "\n",
    "##### The disadvantages of Multi-layer Perceptron are:\n",
    "- MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.\n",
    "- MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.\n",
    "- MLP is sensitive to feature scaling.\n",
    "\n",
    "##### How it works: \n",
    "- MLP trains using Backpropagation. \n",
    "- More precisely, it trains using some form of gradient descent and the gradients are calculated using Backpropagation. \n",
    "- For classification, it minimizes the Cross-Entropy loss function. \n",
    "\n",
    "##### About the parameters: \n",
    "- Alpha: \n",
    " - (L2 regularization) term which helps in avoiding overfitting by penalizing weights with large magnitudes.\n",
    "- Activation\n",
    " - Softmax:  Notice that no matter what values are plugged into predict_proba(), the output probability vector always sums up to 1. This can only be achieved by the Softmax activation function. Using an activation other that Softmax there is no guarantee that the sum of the activations in the final layer will be exactly one, specially for an unseen sample\n",
    "- Solvers: \n",
    "  - Empirically, we observed that L-BFGS converges faster and with better solutions on small datasets. \n",
    "  - For relatively large datasets, however, Adam is very robust. It usually converges quickly and gives pretty good performance. \n",
    "  - SGD with momentum or nesterov’s momentum, on the other hand, can perform better than those two algorithms if learning rate is correctly tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the MLP classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'solver': ['adam', 'lbfgs'], 'alpha': array([  1.00000e-01,   1.00000e-02,   1.00000e-03,   1.00000e-04,\n",
       "         1.00000e-05,   1.00000e-06])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='neg_log_loss',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(  MLPClassifier(), \n",
    "        param_grid={\n",
    "        'alpha': 10.0 ** -np.arange(1, 7),     \n",
    "        'solver': ['adam', 'lbfgs'],\n",
    "         }, \n",
    "        scoring = 'neg_log_loss')         #use scoring = neg_log_loss (so it knows that lower is better)\n",
    "\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred2 = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of Lows:  78.35143459231642\n",
      "percentage of Mediums:  17.020586804992703\n",
      "percentage of Highs:  4.627978602690874\n"
     ]
    }
   ],
   "source": [
    "print(\"percentage of Lows: \", len(y_pred2[y_pred2 == 1])/len(y_pred2) * 100)\n",
    "print(\"percentage of Mediums: \", len(y_pred2[y_pred2 == 2])/len(y_pred2) * 100)\n",
    "print(\"percentage of Highs: \", len(y_pred2[y_pred2 == 3])/len(y_pred2)* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.61349172e-01,   4.95775261e-01,   1.42875567e-01],\n",
       "       [  9.41301132e-01,   5.73203208e-02,   1.37854721e-03],\n",
       "       [  2.05067442e-01,   3.04701411e-01,   4.90231146e-01],\n",
       "       ..., \n",
       "       [  9.98763774e-01,   1.23229413e-03,   3.93160251e-06],\n",
       "       [  4.48459735e-01,   4.30502389e-01,   1.21037876e-01],\n",
       "       [  5.21456940e-01,   3.32636886e-01,   1.45906174e-01]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba2 = gs.predict_proba(X_test)\n",
    "y_pred_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss from grid search parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66355456222180464"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(\"log loss from grid search parameters:\")\n",
    "log_loss(y_test, y_pred_proba2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Other things to try in grid search: \n",
    "        #\"random_state\" = 1,\n",
    "    #'hidden0__units': [4, 8, 12],\n",
    "    #'activation': [\"relu\", \"logistic\", \"Tanh\"],\n",
    "        #'learning_rate': [0.005, 0.001],\n",
    "        #hidden_layer_sizes=(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'solver': 'adam', 'alpha': 0.10000000000000001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(gs.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-2,\n",
    "                   hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.62389776, -0.61783595, -0.6190104 , -0.63598702, -0.6368969 ])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Stratigied K-fold perserves the number of examples from each class \n",
    "cv_scores = cross_val_score(clf, X_train_all_scale, y_train_all, scoring='neg_log_loss', cv = 5) \n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean log loss: 0.626725605282\n"
     ]
    }
   ],
   "source": [
    "print(\"mean log loss:\", -1*np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from MLP classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of Lows:  79.32403955260172\n",
      "percentage of Mediums:  20.675960447398282\n",
      "percentage of Highs:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"percentage of Lows: \", len(y_pred[y_pred== 1])/len(y_pred) * 100)\n",
    "print(\"percentage of Mediums: \", len(y_pred[y_pred== 2])/len(y_pred) * 100)\n",
    "print(\"percentage of Highs: \", len(y_pred[y_pred== 3])/len(y_pred)* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(822, 5), (5, 2), (2, 3)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.coefs_ contains the weight matrices that constitute the model parameters:\n",
    "[coef.shape for coef in clf.coefs_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32654734,  0.39491991,  0.27853275],\n",
       "       [ 0.91528705,  0.08025899,  0.00445396],\n",
       "       [ 0.38119487,  0.4153941 ,  0.20341103],\n",
       "       ..., \n",
       "       [ 0.97597012,  0.02242089,  0.00160899],\n",
       "       [ 0.37515921,  0.4136875 ,  0.2111533 ],\n",
       "       [ 0.74149368,  0.19757999,  0.06092633]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64433181807869266"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log loss of acutal vs. predicting on the testing data (not the holdout data yet)\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_pred_proba)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69962716809855729"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent accuracy \n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logloss = 0.62709157338049504    \n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(5, 2), random_state=1)\n",
    "       \n",
    "logloss = 0.61944758672494526    \n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-2,\n",
    "                   hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a kaggle submission: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 822)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage predicted low label:\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_holdout = gs.predict_proba(X_holdout)\n",
    "y_pred_holdout = gs.predict(X_holdout)\n",
    "\n",
    "print(\"percentage predicted low label:\")\n",
    "print(len(y_pred_holdout[y_pred_holdout== 1])/X_holdout.shape[0]) \n",
    "\n",
    "y_pred_proba_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"listing_id\": holdout[\"listing_id\"],\n",
    "        \"high\": y_pred_proba_holdout[:,2],\n",
    "        \"medium\":y_pred_proba_holdout[:,1],\n",
    "        \"low\": y_pred_proba_holdout[:,0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>high</th>\n",
       "      <th>medium</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7142618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7210040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7174566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7191391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7171695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id  high  medium  low\n",
       "0     7142618   0.0     0.0  1.0\n",
       "1     7210040   0.0     0.0  1.0\n",
       "2     7174566   0.0     0.0  1.0\n",
       "3     7191391   0.0     0.0  1.0\n",
       "4     7171695   0.0     0.0  1.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsTitles=[\"listing_id\",\"high\",\"medium\",\"low\"]\n",
    "submission=submission.reindex(columns=columnsTitles)\n",
    "submission.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other types of Neural Nets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subset to only the integer predictors: \n",
    "\n",
    "ind = list(range(3,17))\n",
    "ind.extend(list(range(20,81)))\n",
    "ind.extend(list(range(110, 441)))\n",
    "ind.extend(list(range(441, 560)))\n",
    "ind.extend(list(range(560, 739)))\n",
    "ind.extend(list(range(739, 767)))\n",
    "ind.extend(list(range(767,825)))\n",
    "X_train_all_ints = mat_train[:,ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test/train split:   \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train_int, X_test_int, y_train_int, y_test_int = train_test_split(X_train_all_ints, y_train_all)    # could also try stratified K_fold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "gnb = MultinomialNB()\n",
    "gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = gnb.fit(X_train_int, y_train_int).predict(X_test_int)\n",
    "y_pred_proba = gnb.fit(X_train_int, y_train_int).predict_proba(X_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.328615662322395"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test_int, y_pred_proba)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 12338 points : 10159\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (X_test_int.shape[0],(y_test_int != y_pred).sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
