{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read in the data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Data has been formatted for neural nets:\n",
    "- Binary columns are encoded as -1/1 instead of as 0/1. \n",
    "- All columns are then scaled. \n",
    "- Categorical columns are one-hot encoded. \n",
    "- A few outliers removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#note: these files do have headers \n",
    "\n",
    "train1 = pd.read_csv(\"lara_1_train.csv\")    #The training data\n",
    "test1 = pd.read_csv(\"lara_1_test.csv\")      #Holdout data for testing on Kaggle\n",
    "\n",
    "ytrain1 = pd.read_csv(\"y_1_train.csv\")      #Training labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#convert from pandas to numpy arrays:\n",
    "train1 = train1.as_matrix()\n",
    "test1 = test1.as_matrix()\n",
    "ytrain1 = np.array(ytrain1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 74)\n",
      "(74659, 74)\n",
      "(49352,)\n"
     ]
    }
   ],
   "source": [
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(ytrain1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For train/test splitting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split \n",
    "#X_train, X_test, y_train, y_test = train_test_split(train1, ytrain1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "log loss I got from this model on Kaggle: 0.62556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model1 = MLPClassifier(activation = 'tanh', \n",
    "                    alpha =  1.0000000000000001e-05,\n",
    "                    hidden_layer_sizes = (4,) ,\n",
    "                    solver = 'sgd' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model1.fit(train1, ytrain1)\n",
    "y_pred_mod1 = model1.predict(test1)\n",
    "y_pred_proba_mod1 = model1.predict_proba(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For finding the log loss on a train/test split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(\"log loss on the test set :\")\n",
    "#log_loss(y_test, y_pred_proba_mod1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import regularizers\n",
    "from keras import callbacks\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers, initializers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Keras needs the labels to be in binary 0/1 vectors for each class: \n",
    "#categorical_labels_train = to_categorical(ytrain1-1, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#scale = StandardScaler()\n",
    "#train1 = scale.fit_transform(train1)\n",
    "#test1 = scale.fit_transform(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data with the above 2 steps completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 =  pd.read_csv(\"train1_allscaled.csv\")    #The training data\n",
    "categorical_labels_train = pd.read_csv(\"categorical_labels_train.csv\")      #Training labels \n",
    "\n",
    "test1 = pd.read_csv(\"test1_allscaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert from pandas to numpy arrays:\n",
    "train1 = train1.as_matrix()\n",
    "test1 = test1.as_matrix()\n",
    "categorical_labels_train = np.array(categorical_labels_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 74)\n",
      "(74659, 74)\n",
      "(49352, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(categorical_labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "22710/49352 [============>.................] - ETA: 10s - loss: 0.7966 - acc: 0.6573"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "inshape = train1.shape[1]\n",
    "\n",
    "#Input layer: \n",
    "model4.add(Dense(50, input_dim= inshape, activation = 'tanh',         \n",
    "                #kernel_regularizer=regularizers.l2(0.001),\n",
    "                #activity_regularizer=regularizers.l1(0.001), \n",
    "                kernel_initializer= initializers.glorot_normal(seed=None)))\n",
    "                     \n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))     \n",
    "\n",
    "#One hidden layer: \n",
    "model4.add(Dense(50,  activation = 'tanh',\n",
    "                #kernel_regularizer=regularizers.l2(0.001),\n",
    "                #activity_regularizer=regularizers.l1(0.001), \n",
    "                kernel_initializer= initializers.glorot_normal(seed=None)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "#Second hidden layer: \n",
    "model4.add(Dense(50, activation = 'tanh', \n",
    "                #kernel_regularizer=regularizers.l2(0.01),\n",
    "                #activity_regularizer=regularizers.l1(0.01), \n",
    "                kernel_initializer= initializers.glorot_normal(seed=None)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "#Output layer \n",
    "model4.add(Dense(3, activation='softmax',\n",
    "                #kernel_regularizer=regularizers.l2(0.01),\n",
    "                #activity_regularizer=regularizers.l1(0.01), \n",
    "                kernel_initializer= initializers.glorot_normal(seed=None)))\n",
    "\n",
    "#Setting up to optimize the weights: \n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#change verbose to 0 to stop printing the progress: \n",
    "model4.fit(train1,categorical_labels_train, epochs=150, batch_size=10, verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "mean cross-validated testing log loss from this model :\n",
    "0.612296414625 +/- 0.00209871497037"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
